flights <- mutate(flights, time_gain = arr_delay - dep_delay)
colnames(flights)
View(flights)
# Use `dplyr` to sort your data frame in descending order by the column you just
# created. Remember to save this as a variable (or in the same one!)
flights <- arrange(flights, desc(time_gain))
flights <- mutate(flights, time_gain = arr_delay - dep_delay) %>%
arrange(flights, desc(time_gain))
View(flights)
flights <- flights %>% mutate(flights, time_gain = arr_delay - dep_delay) %>%
arrange(flights, desc(time_gain))
# For practice, repeat the last 2 steps in a single statement using the pipe
# operator. You can clear your environmental variables to "reset" the data frame
flights <- flights %>% mutate(time_gain = arr_delay - dep_delay) %>% arrange(desc(time_gain))
# Make a histogram of the amount of time gained using the `hist()` function
hist(flights$time_gain)
# On average, did flights gain or lose time?
# Note: use the `na.rm = TRUE` argument to remove NA values from your aggregation
mean(flights$time_gain, na.rm = TRUE)
# Create a data.frame of flights headed to SeaTac ('SEA'), only including the
# origin, destination, and the "gain_in_air" column you just created
seatac <- flights %>% select(origin, dest, time_gain) %>% filter(dest == "SEA")
View(seatac)
View(flights)
# Exercise 4: practicing with dplyr
# Install the `nycflights13` package. Load (`library()`) the package.
# You'll also need to load `dplyr`
install.packages("nycflights13")
library("nycflights13")
# The data frame `flights` should now be accessible to you.
# Use functions to inspect it: how many rows and columns does it have?
# What are the names of the columns?
# Use `??flights` to search for documentation on the data set (for what the
# columns represent)
nrow(flights)
ncol(flights)
colnames(flights)
??flights
# Use `dplyr` to give the data frame a new column that is the amount of time
# gained or lost while flying (that is: how much of the delay arriving occured
# during flight, as opposed to before departing).
flights <- mutate(flights, time_gain = arr_delay - dep_delay)
# Use `dplyr` to sort your data frame in descending order by the column you just
# created. Remember to save this as a variable (or in the same one!)
flights <- arrange(flights, desc(time_gain))
# For practice, repeat the last 2 steps in a single statement using the pipe
# operator. You can clear your environmental variables to "reset" the data frame
flights <- flights %>% mutate(time_gain = arr_delay - dep_delay) %>% arrange(desc(time_gain))
# Make a histogram of the amount of time gained using the `hist()` function
hist(flights$time_gain)
# On average, did flights gain or lose time?
# Note: use the `na.rm = TRUE` argument to remove NA values from your aggregation
mean(flights$time_gain, na.rm = TRUE)
# Create a data.frame of flights headed to SeaTac ('SEA'), only including the
# origin, destination, and the "gain_in_air" column you just created
seatac <- flights %>% select(origin, dest, time_gain) %>% filter(dest == 'SEA')
# On average, did flights to SeaTac gain or loose time?
# Consider flights from JFK to SEA. What was the average, min, and max air time
# of those flights? Bonus: use pipes to answer this question in one statement
# (without showing any other data)!
install.packages("nycflights13")
# On average, did flights to SeaTac gain or loose time?
mean(seatac$time_gain, na.rm = TRUE)
?summarize
??summarize
filter(flights, origin == 'JFK', dest == 'SEA') %>%
summarize(avg_air_time = mean(air_time, na.rm = TRUE),
max_air_time = max(air_time, na.rm = TRUE),
min_air_time = min(air_time, na.rm = TRUE))
filter(flights, origin=="JFK", dest=="SEA") %>%
summarize(
avg_air_time = mean(air_time, na.rm = TRUE),
max_air_time = max(air_time, na.rm = TRUE),
min_air_time = min(air_time, na.rm = TRUE)
)
flights %>% filter(origin == 'JFK', dest == 'SEA') %>%
summarize(avg_air_time = mean(air_time, na.rm = TRUE),
max_air_time = max(air_time, na.rm = TRUE),
min_air_time = min(air_time, na.rm = TRUE))
filter(origin == 'JFK', dest == 'SEA') %>%
summarize(avg_air_time = mean(air_time, na.rm = TRUE),
max_air_time = max(air_time, na.rm = TRUE),
min_air_time = min(air_time, na.rm = TRUE))
origin == 'JFK', dest == 'SEA') %>%
summarize(avg_air_time = mean(air_time, na.rm = TRUE),
max_air_time = max(air_time, na.rm = TRUE),
min_
filter(flights, origin == 'JFK', dest == 'SEA') %>%
summarize(avg_air_time = mean(air_time, na.rm = TRUE),
max_air_time = max(air_time, na.rm = TRUE),
min_air_time = min(air_time, na.rm = TRUE))
install.packages("dplyr")
library(dplyr)
filter(flights, origin == 'JFK', dest == 'SEA') %>%
summarize(avg_air_time = mean(air_time, na.rm = TRUE),
max_air_time = max(air_time, na.rm = TRUE),
min_air_time = min(air_time, na.rm = TRUE))
# What was the average departure delay in each month?
# Save this as a data frame `dep_delay_by_month`
# Hint: you'll have to perform a grouping operation then summarizing your data
# Exercise 5: dplyr grouped operations
# Install the `nycflights13` package. Load (`library()`) the package.
# You'll also need to load `dplyr`
#install.packages("nycflights13")  # should be done already
library(nycflights13)
library(dplyr)
# What was the average departure delay in each month?
# Save this as a data frame `dep_delay_by_month`
# Hint: you'll have to perform a grouping operation then summarizing your data
# Which month had the greatest average departure delay?
# If your above data frame contains just two columns (e.g., "month", and "delay" in that order), you can create
# a scatterplot by passing that data frame to the 'plot()' function
# To which destinations were the average arrival delays the highest?
# Hint: you'll have to perform a grouping operation then summarize your data
# You can use the `head()` function to view just the first few rows
# You can look up these airports in the `airports` data frame!
# Which city was flown to with the highest average speed?
dep_delay_by_month <- flights %>% group_by(month) %>% summarize(delay = mean(dep_delay, na.rm=TRUE))
dep_delay_by_month
# Which month had the greatest average departure delay?
filter(dep_delay_by_month, delay == max(delay)) %>% select(month)
# If your above data frame contains just two columns (e.g., "month", and "delay" in that order), you can create
# a scatterplot by passing that data frame to the 'plot()' function
plot(dep_delay_by_month)
arr_delay_by_month <- flights %>% group_by(dest) %>% summarise(delay = mean(arr_delay, na.rm=TRUE)) %>% arrange(-delay)
head(arr_delay_by_month)
avg_delay <- flights %>% group_by(dest) %>% summarise(delay = mean(arr_delay, na.rm=TRUE)) %>% arrange(-delay)
head(avg_delay)
# You can look up these airports in the `airports` data frame!
# Which city was flown to with the highest average speed?
highest_avg_speed <- flights %>%
mutate(speed = distance/air_time * 60) %>%
group_by(dest) %>%
summarise(avg_speed = mean(speed, na.rm = TRUE)) %>%
filter(avg_speed == max(avg_speed, na.rm = TRUE))
library(httr)
library(jsonlite)
library(dplyr)
# Create a variable for the API's base URI (https://api.github.com)
base_uri <- "https://api.github.com"
# Under the "Repositories" category of the API,
# find the endpoint that will list repos in an organization. Then,
# Create a variable `resource` that stores the endpoint for the "info201"
# organization repos (this is the PATH to the resource of interest).
# (FYI: this is where we keep the book code and master exercise sets!)
resource <- "orgs/info201/repos"
GET(paste0(base_uri, resource))
# Under the "Repositories" category of the API,
# find the endpoint that will list repos in an organization. Then,
# Create a variable `resource` that stores the endpoint for the "info201"
# organization repos (this is the PATH to the resource of interest).
# (FYI: this is where we keep the book code and master exercise sets!)
resource <- "/orgs/info201/repos"
# Send a GET request to this endpoint (the `base_uri`` followed by `resource`)
GET(paste0(base_uri, resource))
result <- GET(paste0(base_uri, resource))
# Extract the "text" of the response usin the `content` function
text <- content(result, "text")
# Convert the body from JSON into a data frame
body <- fromJSON(text)
# How many (public) repositories does the organization have?
repos <- nrow(body)
repos
ce <- "/search/repositories"
# You will need to specify some query parameters. Create a `query_params` list
# variable that specifies an appropriate key and value for the search term and
# the language
query_params <- list(q = "graphics")
# Send a GET request to this endpoint--including your params list as the `query`
result
# Extract the response body and convert it from JSON.
json <- fromJSON(content(result2, "text"))
# Send a GET request to this endpoint--including your params list as the `query`
result2 <- GET(paste0(base_uri, resource), query_params)
# Extract the response body and convert it from JSON.
json <- fromJSON(content(result2, "text"))
colnames(json)
bod <- content(result2, "text")
json <- fromJSON(bod)
colnames(bod)
query_params <- list(q = "graphics+language:R")
# Send a GET request to this endpoint--including your params list as the `query`
response <- GET(paste0(base_uri, resource), query = query_params)
# Extract the response body and convert it from JSON.
body <- content(response, "text")
results <- fromJSON(body)
# How many search repos did your search find? (Hint: check the list names)
print(results$total_count)
# Install and load the `ggplot2` package
# You will also want to load `dplyr`
install.packages("ggplot2")
library(ggplot2)
library(dplyr)
# For this exercise you'll be working with the `diamonds` data set included in
# the ggplot2 library
# Use `?diamonds` to get more information about this data set (including the
# column descriptions. Also check the _column names_ and the _number of rows_
# in the data set
?diamonds
colnames(diamonds)
nrow(diamonds)
?sample_n
# This data set has A LOT of rows. To make things a bit more readable,
# use dplyr's `sample_n()` function to get a random 1000 rows from the data set
# Store this sample in a variable `diamonds_sample`
diamond_sample <- sample_n(diamonds, 1000)
nrow(diamond_sample)
# Start by making a new `ggplot` with the `diamonds_sample` as the data (no
# geometry yet)
# What do you see? (What did you expect?)
ggplot(diamond_sample)
# Start by making a new `ggplot` with the `diamonds_sample` as the data (no
# geometry yet)
# What do you see? (What did you expect?)
ggplot(data=diamond_sample)
ggplot(data=diamond_sample) +
geom_point(mapping = aes(x = carat, y = price))
ggplot(data=diamond_sample) +
geom_point(mapping = aes(x = carat, y = price, color = clarity))
ggplot(data=diamond_sample) +
geom_point(mapping = aes(x = carat, y = price, color = class))
ggplot(data=diamond_sample) +
geom_point(mapping = aes(x = carat, y = price, color = clarity))
ggplot(data=diamond_sample) +
geom_point(mapping = aes(x = carat, y = price, color = clarity))
ggplot(data=diamond) +
geom_point(mapping = aes(x = carat, y = price, color = clarity))
ggplot(data=diamonds) +
geom_point(mapping = aes(x = carat, y = price, color = clarity))
# Hint: you'll need to set the color channel, not map a value to it!
ggplot(data=diamond_sample) +
geom_point(mapping = aes(x = price, y = carat, color = "blue"))
ggplot(data=diamond_sample) +
geom_point(mapping = aes(x = price, y = carat), color = "blue")
colnames(diamond_sample)
ggplot(data=diamond_sample) +
geom_point(mapping = aes(x = price, y = carat, shape = cut))
ggplot(data = diamonds_sample) +
geom_point(mapping = aes(x = carat, y = cut, size = price))
ggplot(data = diamond_sample) +
geom_point(mapping = aes(x = carat, y = cut, size = price))
ggplot(data = diamond_sample) +
geom_point(mapping = aes(x = carat, y = cut, size = price, color = price))
# Exercise 2: advanced ggplot2 practice
# Install and load the `ggplot2` package
#install.packages('ggplot2')
library(ggplot2)
# For this exercise you will again be working with the `diamonds` data set.
# Use `?diamonds` to review details about this data set
?diamonds
## Statistical Transformations
# Draw a bar chart of the diamonds data, organized by cut
# Each bar's height is based on the "count" (number) of diamonds with that cut
ggplot(data = diamonds) +
geom_bar(mapping = aes(x = cut))
# Use the `stat_count` to apply the statistical transformation "count" to the
# diamonds by cut. You do not need a separate geometry layer!
# Use the `stat_summary` function to draw a chart with a summary layer.
# Map the x-position to diamond `cut`, and the y-position to diamond `depth`
# Bonus: use `min` as the function ymin, `max` as the function ymax, and `median`
# as the function y
## Position Adjustments
# Draw a bar chart of diamonds organized by cut, with each bar filled by clarity.
# You should see a _stacked_ bar chart.
# Draw the same chart again, but with each element positioned to "fill" the y axis
# Draw the same chart again, but with each element positioned to "dodge" each other
# Draw a plot with point geometry with the x-position mapped to `cut` and the
# y-position mapped to `clarity`
# This creates a "grid" grouping the points
# Use the "jitter" position adjustment to keep the points from all overlapping!
# (This works a little better with a sample of diamond data, such as from the
# previous exercise).
## Scales
# Draw a "boxplot" (with `geom_boxplot`) for the diamond's price (y) by color (x)
# This has a lot of outliers, making it harder to read. To fix this, draw the
# same plot but with a _logarithmic_ scale for the y axis.
# For another version, draw the same plot but with `violin` geometry instead of
# `boxplot` geometry!
# How does the logarithmic scale change the data presentation?
# Another interesting plot: draw a plot of the diamonds price (y) by carat (x),
# using a heatmap of 2d bins (geom_bin2d)
# What happens when you make the x and y channels scale logarithmically?
# Draw a scatter plot for the diamonds price (y) by carat (x). Color each point
# by the clarity (Remember, this will take a while. Use a sample of the diamonds
# for faster results)
# Change the color of the previous plot using a ColorBrewer scale of your choice.
# What looks nice?
## Coordinate Systems
# Draw a bar chart with x-position and fill color BOTH mapped to cut
# For best results, SET the `width` of the geometry to be 1 (fill plot, no space
# between)
# TIP: You can save the plot to a variable for easier modifications
# Draw the same chart, but with the coordinate system flipped
# Draw the same chart, but in a polar coordinate system. It's a Coxcomb chart!
## Facets
# Take the scatter plot of price by carat data (colored by clarity) and add
# _facets_ based on the diamond's `color`
## Saving Plots
# Use the `ggsave()` function to save the current (recent) plot to disk.
# Name the output file "my-plot.png".
# Make sure you've set the working directory!!
# diamonds by cut. You do not need a separate geometry layer!
ggplot(data = diamonds) +
stat_count(mapping = aes(x = cut))
colnames(diamonds)
ggplot(data = diamonds) +
stat_summary(mapping = aes(x = cut, y = depth))
# diamonds by cut. You do not need a separate geometry layer!
ggplot(data = diamonds) +
stat_summary(mapping = aes(x = cut, y = depth),
fun.ymin = min, fun.ymax = max, fun.y = median)
ggplot(data = diamonds) +
geom_bar(mapping = aes(x = cut, color = clarity))
ggplot(data = diamonds) +
geom_bar(mapping = aes(x = cut, fill = clarity))
ggplot(data = diamonds) +
geom_bar(mapping = aes(x = cut, fill = clarity), position = "fill")
ggplot(data = diamonds) +
geom_bar(mapping = aes(x = cut, fill = clarity), position = "dodge")
ggplot(data = diamonds) +
geom_point(mapping = aes(x = cut, y = clarity))
ggplot(data = diamonds) +
geom_point(mapping = aes(x = cut, y = clarity), postition = "jitter")
ggplot(data = diamonds) +
geom_point(mapping = aes(x = cut, y = clarity), position = "jitter")
ggplot(data = diamonds) +
geom_boxplot(mapping = aes(x = color, y = price))
ggplot(data = diamonds) +
geom_boxplot(mapping = aes(x = color, y = price)) +
scale_y_log10()
ggplot(data = diamonds) +
geom_violin(mapping = aes(x = color, y = price)) +
scale_y_log10()
shiny::runApp('Documents/INFO201/INFO_Group_Collab')
runApp('Documents/INFO201/INFO_Group_Collab')
runApp('Documents/INFO201/INFO_Group_Collab')
library(ggplot2)
library(stringr)
library(dplyr)
createPledgedPlot <- function(dataset) {
dataset <- read.csv("./data/ks-projects-201612.csv", stringsAsFactors = FALSE)
}
View(dataset)
dataset <- read.csv("./data/ks-projects-201612.csv", stringsAsFactors = FALSE)
View(dataset)
dataset <- read.csv("./data/ks-projects-201612.csv", stringsAsFactors = FALSE)
dataset <- read.csv("../data/ks-projects-201612.csv", stringsAsFactors = FALSE)
View(dataset)
setwd("~/Documents/INFO201/INFO_Group_Collab")
dataset <- read.csv("./data/ks-projects-201612.csv", stringsAsFactors = FALSE)
View(dataset)
colnames(dataset)
dataset2 <- read.csv("./data/ks-projects-201801.csv", stringsAsFactors = FALSE)
colnames(dataset2)
View(dataset2)
runApp()
runApp()
runApp()
View(dataset2)
colnames(dataset2)
View(dataset2)
ggplot(data = dataset2) +
geom_point(mapping = aes(x = usd_goal_real, y = usd_pledged_real))
p <- ggplot(data = dataset2) +
geom_point(mapping = aes(x = usd_goal_real, y = usd_pledged_real))
p
p
library(dplyr)
filtered <- dataset2 %>% filter(category == "Food")
p <- ggplot(data = filtered) +
geom_point(mapping = aes(x = usd_goal_real, y = usd_pledged_real))
p
p <- ggplot(data = filtered) +
geom_point(mapping = aes(x = usd_goal_real, y = usd_pledged_real)) +
xlim(0, 1000) +
ylim(0, 1000)
p
p <- ggplot(data = filtered) +
geom_point(mapping = aes(x = usd_goal_real, y = usd_pledged_real)) +
xlim(0, 10000) +
ylim(0, 10000)
p
p <- ggplot(data = filtered) +
geom_point(mapping = aes(x = usd_goal_real, y = usd_pledged_real)) +
xlim(0, 1000000) +
ylim(0, 1000000)
p
p <- ggplot(data = filtered) +
geom_point(mapping = aes(x = usd_goal_real, y = usd_pledged_real)) +
xlim(0, 1000000) +
ylim(0, 1000000)
p
p <- ggplot(data = filtered) +
geom_point(mapping = aes(x = usd_goal_real, y = usd_pledged_real)) +
xlim(0, 500000) +
ylim(0, 500000)
p
colnames(filtered)
p <- ggplot(data = filtered) +
geom_point(mapping = aes(x = usd_goal_real, y = usd_pledged_real, color = backers)) +
xlim(0, 500000) +
ylim(0, 500000)
p
p <- ggplot(data = filtered) +
geom_point(mapping = aes(x = usd_goal_real, y = usd_pledged_real, color = backers, stat = "identity")) +
xlim(0, 500000) +
ylim(0, 500000)
p <- ggplot(data = filtered) +
geom_point(mapping = aes(x = usd_goal_real, y = usd_pledged_real, color = factor(backers))) +
xlim(0, 500000) +
ylim(0, 500000)
p
p <- ggplot(data = filtered) +
geom_point(mapping = aes(x = usd_goal_real, y = usd_pledged_real, color = factor(backers))) +
scale_color_gradient(low="blue", high="red")+
xlim(0, 500000) +
ylim(0, 500000)
p
p <- ggplot(data = filtered) +
geom_point(mapping = aes(x = usd_goal_real, y = usd_pledged_real, color = factor(backers))) +
scale_colour_gradient(low="blue", high="red")+
xlim(0, 500000) +
ylim(0, 500000)
p
p <- ggplot(data = filtered) +
geom_point(mapping = aes(x = usd_goal_real, y = usd_pledged_real, color = factor(backers))) +
# scale_colour_gradient(low="blue", high="red") +
xlim(0, 500000) +
ylim(0, 500000)
p
p <- ggplot(data = filtered) +
geom_point(mapping = aes(x = usd_goal_real, y = usd_pledged_real, color = backers)) +
scale_colour_gradient(low="blue", high="red") +
xlim(0, 500000) +
ylim(0, 500000)
p
p <- ggplot(data = filtered) +
geom_point(mapping = aes(x = usd_goal_real, y = usd_pledged_real, color = backers)) +
scale_colour_gradient(low="pink", high="red") +
xlim(0, 500000) +
ylim(0, 500000)
p
p <- ggplot(data = filtered) +
geom_point(mapping = aes(x = usd_goal_real, y = usd_pledged_real, color = main_category)) +
# scale_colour_gradient(low="pink", high="red") +
xlim(0, 500000) +
ylim(0, 500000)
p
filtered <- dataset2 %>% filter(main_category == "Games")
p <- ggplot(data = filtered) +
geom_point(mapping = aes(x = usd_goal_real, y = usd_pledged_real, color = category)) +
# scale_colour_gradient(low="pink", high="red") +
xlim(0, 500000) +
ylim(0, 500000)
p
p <- ggplot(data = filtered) +
geom_point(mapping = aes(x = usd_goal_real, y = usd_pledged_real, color = category)) +
# scale_colour_gradient(low="pink", high="red") +
xlim(0, 500000) +
ylim(0, 500000) +
labs(x = "Goal (USD)", y = "Pledged (USD)")
p
p
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
mainCategories <- dataset %>% select(main_category) %>% distinct()
View(mainCategories)
mainCategories <- dataset %>%
group_by(main_category) %>%
order_by(n()) %>%
select(main_category)
mainCategories <- dataset %>% select(main_category) %>% distinct()
mainCategories <- dataset %>% group_by(main_category) %>% summarise(count = n())
mainCategories
mainCategories <- dataset %>% group_by(main_category) %>% summarise(count = n()) %>% order_by(count)
mainCategories <- dataset %>% group_by(main_category) %>% summarise(count = n())
mainCategories <- dataset %>% group_by(main_category) %>% summarise(count = n()) %>% arrange(-count)
View(mainCategories)
categ <- as.vector(mainCategories$main_category)
categ
categ <- as.vector(mainCategories$main_category)[1:15]
categ
topCategories <- as.list(mainCategories$main_category)[1:15]
topCategories
topCategories <- as.list(as.vector((mainCategories$main_category)[1:15])
p <- ggplot(data = filtered) +
geom_point(mapping = aes(x = usd_goal_real, y = usd_pledged_real, color = category)) +
xlim(goalRange[1], goalRange[2]) +
ylim(pledgedRange[1], pledgedRange[2]) +
labs(x = "Goal (USD)", y = "Pledged (USD)")
p
}
topCategories <- as.list(as.vector((mainCategories$main_category)[1:15]))
topCategories
topCategories <- as.list(mainCategories$main_category)
topCategories
topCategories
topCategories <- as.list(mainCategories$main_category)[1:15]
topCategories <- as.list(mainCategories$main_category)[1:15]
topCategories
names(topCategories) <- mainCategories$main_category[1:15]
topCategories
topCategories <- as.vector(mainCategories$main_category)[1:15]
topCategories
runApp()
runApp()
runApp()
runApp()
